{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in your name, student id number and email address\n",
    "#### name:\n",
    "#### student id:\n",
    "#### email:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis and knowledge discovery - Exercise 3: Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the template for the third exercise. The purpose of this exercise is to familiarize yourself with the basics of unsupervised learning by using the agglomerative hierarchical clustering and k-means clustering algorithms to find patterns.\n",
    "\n",
    "This exercise uses the wine dataset, available on moodle as `ex3_wine.csv`. The features are all numeric. They quantify chemical properties of wine, grown around the same area in Italy. The feature names are listed in the table below.\n",
    "\n",
    "| Feature | Type \n",
    "| :--- | ---: \n",
    "| Alcohol | Numeric (float)\n",
    "| Malic acid | Numeric (float)\n",
    "| Ash | Numeric (float)\n",
    "| Alcalinity of ash | Numeric (float)\n",
    "| Magnesium | Numeric (integer)\n",
    "| Total phenols | Numeric (float)\n",
    "| Flavanoids | Numeric (float)\n",
    "| Nonflavanoid phenols | Numeric (float)\n",
    "| Proanthocyanins | Numeric (float)\n",
    "| Color intensity | Numeric (float)\n",
    "| Hue | Numeric (float)\n",
    "| OD280/OD315 of diluted wines | Numeric (float)\n",
    "| Proline | Numeric (integer)\n",
    "\n",
    "\n",
    "In real applications, visualizing various aspects of the data the data and data scrubbing are important steps. However, in this exercise you can treat the data as given, and focus on the unsupervised methods.\n",
    "\n",
    "Please consider the following things when returning your notebook:\n",
    "\n",
    " - As in the two previous exercises, the grading scale is failed/passed/passed with honors.\n",
    " - **For a passing grade, Parts 1-3 must be complete**, and all questions in each of them should be answered. Some mistakes are allowed as long as you clearly attempt to solve all the exercises.\n",
    " - For completing Parts 1-3 and the optional bonus Part 4 sufficiently well, you will be awarded one bonus point for the exam.\n",
    " - All the cells in the finished notebook should run without crashing. Please delete unnecessary cells. As a good rule of thumb, use **\"Restart Kernel and Run All Cells\"** on your finished notebook to make sure it runs without errors and produces the expected output.\n",
    " - Comment your code to explain how it works and what you intend for it to do.\n",
    " - Answer the questions asked in the assignments in Markdown cells.\n",
    " - If you're having trouble with this exercise, try an online search first, but **don't just copy-paste code you find**. See exercise guidelines in the Moodle page of this course. If you can't find a solution to your problem, **ask for advice at the exercise sessions** or in the course discussion forum on Moodle or email oskari.s.heikkinen@utu.fi.\n",
    " - If/when you look things up during this exercise, please **cite your sources**, e.g. a link to a web page. It's better to cite too much than too little.\n",
    " - **We don't encourage using a large language model (LLM) such as ChatGPT while doing these exercises.** However, if you do use an LLM, be critical of its output. Understand any code the LLM produced before using the code, don't just copy-paste it. If you used one, write a short description of how you used the LLM in the context of these exercises (what was your input, how did you benefit from the output?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library imports, Jupyter Notebook settings etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below libraries are sufficient to complete the exercise. You can import additional modules here if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools # has some utilities that may be useful in the exercise\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# IPython magic command to display matplotlib figures together with the output\n",
    "# (Often the default setting in a Jupyter Notebook context, so your figures probably work fine without it)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Read the data\n",
    "\n",
    "- Download the exercise 3 data on the Moodle page of this course. (`ex3_wine.csv`)\n",
    "- Read the data into a Pandas dataframe.\n",
    "- Display a few rows and some basic information to make sure the data was loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preprocess and visualize the data\n",
    "\n",
    " - Perform z-score standardization on the features to ensure that all features have the same scale.\n",
    " - Project the data to two dimensions by using principal component analysis (PCA) and visualize the resulting two-dimensional data in a scatter plot. Don't color the scatter plot yet.\n",
    " - Does it look like there are clear clusters? Don't worry if they're hard to see. There may be more than one \"correct\" answer.\n",
    " - Draw shapes (for example `matplotlib.patches.Ellipse`) on top of the scatter plot to visualize any clusters you feel you can easily detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: Agglomerative hierarchical clustering\n",
    " \n",
    " - Cluster the data into 2-10 clusters using agglomerative hierarchical clustering.\n",
    " - Try different values for the linkage parameter. (Ward, Single, Average and Complete)\n",
    " - Use the z-score standardized 13-dimensional data for clustering - **don't use the first two principal components for clustering!**\n",
    " - Explain why using the two principal components would be a bad idea for clustering.\n",
    " - Using silhouette score, evaluate the clustering performance for each linkage criterion and number of clusters combination. Sort the results by silhouette score.\n",
    " - Plot the data into a scatter plot again, this time colouring the data points according to the cluster they were assigned to. Use the best 6 clusterings according to silhouette score.\n",
    " - Do some of the clusterings discovered by agglomerative hierarchical clustering correspond to what visually looked like clusters to you in Part 1? It's absolutely fine if they don't.\n",
    "\n",
    "\n",
    "*Tip: you can use `itertools.product` function to get the Cartesian product of the two lists of hyperparameters (number of clusters, linkage criterion)*\n",
    "\n",
    "*Note: it's a common mistake to think that the points in the scatter plot should move when clustering, but they should not. Clustering can be visualized simply by colouring data points on an existing plot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Dendrograms\n",
    "\n",
    " - Plot dendrograms to visualize the merging processes.\n",
    " - For this you will need a linkage matrix. *Hint: while you can extract one from a fitted AgglomerativeClustering object, it is much easier to use the scipy implementation (`scipy.cluster.hierarchy.linkage`).*\n",
    " - Compute the linkage matrix using Ward and Single linkage, and plot the dendrograms using `scipy.cluster.hierarchy.dendrogram`.\n",
    " - Truncate the dendrogram for better readability. You may choose how exactly you want to do the truncation.\n",
    " - How do you interpret the dendrograms? How do they differ?\n",
    "\n",
    "*Note: when truncating a dendrogram, a number in parentheses refers to the amount of samples in a subtree. A number without parentheses is the index of a single sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: _k_-means clustering\n",
    "\n",
    " - Perform _k_-means clustering on the data. Try 2-10 numbers of clusters.\n",
    " - Evaluate the clustering performance using silhouette score.\n",
    " - Choose the best 3 numbers of clusters according to silhouette score that you discovered above, and once again visualize them on a scatter plot of the first two principal components.\n",
    " - Display the centroids of the clusters on the plot. Remember to transform the centroids to the PCA space. Explain why you need to transform the centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 (BONUS): Filling in missing labels using clustering\n",
    "\n",
    "In this bonus exercise, you're given a dataset with almost all of the labels are missing. This is the starting point in semi-supervised learning. Semi-supervised learning in general is beyond the scope of this course, but if you want you can learn more about it, starting e.g. on [the sklearn page for semi-supervised learning](https://scikit-learn.org/stable/modules/semi_supervised.html). **This exercise does not require researching semi-supervised learning, however.**\n",
    "\n",
    "The dataset used in this exercise is a slightly modified version of [the seeds dataset](https://archive.ics.uci.edu/dataset/236/seeds). The features are different properties of wheat seeds. They are divided to three different classes, simply called `target1`, `target2` and `target3` here. The feature names and their data types are listed in the table below. **Use the modified dataset on Moodle, with the filename `ex3_seeds_missinglabels.csv`**\n",
    "\n",
    "| Feature | Type \n",
    "| :--- | ---: \n",
    "| Area | Numeric (float)\n",
    "| Perimeter | Numeric (float)\n",
    "| Compactness | Numeric (float)\n",
    "| Length | Numeric (float)\n",
    "| Width | Numeric (float)\n",
    "| Asymmetry Coefficient | Numeric (float)\n",
    "| Length Groove | Numeric (float)\n",
    "| Target | Categorical (nominal)\n",
    "\n",
    "First, visualize the first two principal components of the dataset in a scatter plot, showing the labels real for data points you were given. Try to see if the labels look like they belong in what look like clusters on the plot.\n",
    "\n",
    "Your task is to use clustering to assign labels to the rows that have an `unknown` value for their label. Do this by first clustering all of the data, and then filling in the unknown values based on which clusters the data points with known values tend to fit in. The details of how exactly you decide which rows get assigned which label are up to you - you can get creative. Describe and justify your thought process, though.\n",
    "\n",
    "Use whichever clustering methods you prefer. You can cluster the data into 3 clusters because you have 3 known labels, but you could also try a higher number of clusters that you can then merge.\n",
    "\n",
    "You are also given the full labels for the dataset in a separate file called `ex3_seeds_labels.csv`. Plot the real labels next to the labels that your clustering attempts predicted.\n",
    "\n",
    "Finally, compute the adjusted Rand index for labels predicted by your clustering solutions and the real labels, and display it along the scatter plots. Rand index is a measure of similarity between two partitions of a set of elements. Adjusted Rand index is corrected for chance using the maximum and expected values of Rand index. Optionally, you can learn more about the Rand index e.g. on [the Wikipedia page for Rand index](https://en.wikipedia.org/wiki/Rand_index). Here you can simply use the `sklearn.metrics.adjusted_rand_score` method imported at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
